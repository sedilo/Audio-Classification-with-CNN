# -*- coding: utf-8 -*-
"""Audio Classification CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FxVBgsyxkoYWn-FtV0-qWLtnvx9TgtME

# Algoritmo para la clasificación de audio mediante uso de CNN

> **Importamos librerias**
"""

# Commented out IPython magic to ensure Python compatibility.
# Basic Libraries

import pandas as pd
import numpy as np

pd.plotting.register_matplotlib_converters()
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV

from sklearn.preprocessing import MinMaxScaler

# Libraries for Classification and building Models

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout
from tensorflow.keras.utils import to_categorical 

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Project Specific Libraries

import os
import librosa
import librosa.display
import tensorflow as tf
import glob 
import skimage
from joblib import dump
from tensorflow import keras

"""Importamos Google Drive para poder conectarnos a los datos."""

from google.colab import drive
drive.mount('/content/drive')

"""**Cargamos y observamos el Dataset**"""

#Analysing CSV Data
df = pd.read_csv("/content/drive/My Drive/Urban Sound/UrbanSound8K.csv", sep=";")

df.head()
df.tail()

"""#METADATOS
Column Names
fsID: The Freesound ID of the recording from which this excerpt (slice) is taken

start The start time of the slice in the original Freesound recording

end: The end time of slice in the original Freesound recording

salience: A (subjective) salience rating of the sound. 1 = foreground, 2 = background.

fold: The fold number (1-10) to which this file has been allocated.

classID: A numeric identifier of the sound class: 0 = air_conditioner 1 = car_horn 2 = children_playing 3 = dog_bark 4 = drilling 5 = engine_idling 6 = gun_shot 7 = jackhammer 8 = siren 9 = street_music

 class: The class name: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.
"""

#Using Librosa to analyse random sound sample - SPECTOGRAM
dat1, sampling_rate1 = librosa.load('/content/drive/My Drive/Urban Sound/fold5/100032-3-0-0.wav')

#Using Librosa to analyse random sound sample - SPECTOGRAM
dat1, sampling_rate1 = librosa.load('/content/drive/My Drive/Urban Sound/fold5/100032-3-0-0.wav')
dat2, sampling_rate2 = librosa.load('/content/drive/My Drive/Urban Sound/fold5/100263-2-0-117.wav')

#Ploting espectogram
plt.figure(figsize=(20, 10))
D = librosa.amplitude_to_db(np.abs(librosa.stft(dat1)), ref=np.max)
plt.subplot(4, 2, 1)
librosa.display.specshow(D, y_axis='linear')
plt.colorbar(format='%+2.0f dB')
plt.title('Linear-frequency power spectrogram')

#Ploting espectogram
plt.figure(figsize=(20, 10))
D = librosa.amplitude_to_db(np.abs(librosa.stft(dat2)), ref=np.max)
plt.subplot(4, 2, 1)
librosa.display.specshow(D, y_axis='linear')
plt.colorbar(format='%+2.0f dB')
plt.title('Linear-frequency power spectrogram')

#Using random samples to observe difference in waveforms

arr = np.array(df["slice_file_name"])
fold = np.array(df["fold"])
cla = np.array(df["class"])

for i in range(192, 197, 2):
    path = '/content/drive/My Drive/Urban Sound/fold' + str(fold[i]) + '/' + arr[i]
    data, sampling_rate = librosa.load(path)
    plt.figure(figsize=(10, 5))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(data)), ref=np.max)
    plt.subplot(4, 2, 1)
    librosa.display.specshow(D, y_axis='linear')
    plt.colorbar(format='%+2.0f dB')
    plt.title(cla[i])

"""**Feature Extraction and Database Building**

I have used Librosa to extract features.
To do so, I will **go through each fold and extract the data for each file**. Then I have used the mel_spectogram function of librosa to extract the spectogram data as a numpy array.
After reshaping and cleaning the data, 75-25 split has been performed.
Classes (Y) have been converted to Categorically Encoded Data usng Keras.utils

1. Cargamos los datos y extraemos caracteristicas
"""

feature = []
label = []

def parser(row):
    # Function to load files and extract features
    for i in range(8732):
        file_name = '/content/drive/My Drive/Urban Sound/fold' + str(df["fold"][i]) + '/' + df["slice_file_name"][i]
        # Here kaiser_fast is a technique used for faster extraction
        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') 
        # We extract mfcc feature from data
        mels = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)        
        feature.append(mels)
        label.append(df["classID"][i])
    return [feature, label]

temp = parser(df)

temp = np.array(temp)
data = temp.transpose()

"""2. Construimos el dataset"""

X_ = data[:, 0]
Y = data[:, 1]
print(X_.shape, Y.shape)
X = np.empty([8732, 128])

for i in range(8732):
    X[i] = (X_[i])

Y = to_categorical(Y)

#Final data
print(X.shape)
print(Y.shape)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)

X_train = X_train.reshape(6549, 16, 8, 1)
X_test = X_test.reshape(2183, 16, 8, 1)

input_dim = (16, 8, 1)

"""**Creating Keras Model and Testing**

Model:
1. CNN 2D with 64 units and tanh activation.
2. MaxPool2D with 2*2 window.
3. CNN 2D with 128 units and tanh activation.
4. MaxPool2D with 2*2 window.
5. Dropout Layer with 0.2 drop probability.
6. DL with 1024 units and tanh activation.
7. DL 10 units with softmax activation.
8. Adam optimizer with categorical_crossentropy loss function.

    
   90 epochs have been used.
"""

model = Sequential()

#Definimos el modelo tal y como se detalla en la descripción
model.add(Conv2D(64, (3, 3), padding = "same", activation = "tanh", input_shape = input_dim))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Conv2D(128, (3, 3), padding = "same", activation = "tanh"))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.1))
model.add(Flatten())
model.add(Dense(1024, activation = "tanh"))
model.add(Dense(10, activation = "softmax"))

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

#Entrenamos el modelo
model.fit(X_train, Y_train, epochs = 90, batch_size = 50, validation_data = (X_test, Y_test))

model.summary()

predictions = model.predict(X_test)
score = model.evaluate(X_test, Y_test)
print(score)

predictions = model.predict(X_train)
score = model.evaluate(X_train, Y_train)
print(score)

preds = np.argmax(predictions, axis = 1)

result = pd.DataFrame(preds)
result.to_csv("RESULTSUrbanSound8kResults.csv")

"""PARA GUARDAR EL MODELO"""

#dump (model,'Modelo.joblib')

#model.save('Modelo1.h5')

model.save_weights('/content/drive/My Drive/Urban Sound/my_checkpoint')

#saver = tf.train.Saver()
#save_path = saver.save(session, "data/dm.ckpt")
#print("done saving at",save_path)

#import os
#print( os.getcwd() )
#print( os.listdir("data") )

#from google.colab import files
#files.download( "data/dm.ckpt.meta" )

"""CARGAR PESOS Y CREAR UN NUEVO MODELO EN EL QUE PROBARLOS"""

# Define a simple sequential model
def create_model():
  model = tf.keras.models.Sequential([
    keras.layers.Dense(512, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10)
  ])

  model.compile(optimizer='adam',
                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=[tf.metrics.SparseCategoricalAccuracy()])

  return model

# Create a new model instance
model2 = create_model()

# Restore the weights
model2.load_weights('/content/drive/My Drive/Urban Sound/my_checkpoint.index')

# Evaluate the model
loss,acc = model2.evaluate(X_test,  Y_test, verbose=2)
print("Restored model, accuracy: {:5.2f}%".format(100*acc))